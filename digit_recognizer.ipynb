{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Nickfis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# core and utility packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "# modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# keras\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import models\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"/home/Nickfis/Documents/Projects/digit_recognizer/data/train.csv\")\n",
    "test = pd.read_csv(\"/home/Nickfis/Documents/Projects/digit_recognizer/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking structure of data\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking structure of data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "# counting the occurrences of the labels. No imbalance problem. \n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set no longer needed after splitting, deletion for memory space\n",
    "del train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Null and missing values\n",
    "\n",
    "This would tell us about possible corrupted images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data\n",
    "X_train.isnull().any().sum()\n",
    "# no missing data in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().sum()\n",
    "# no missing data in the testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "In context of computer vision, with normalization of data is meant here, to grayscale all the images. This is done on the one hand to reduce the effect of illumination's differences and has a big computational advantage, since now our feature space is just between 0 and 1, instead of ranging from 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape\n",
    "\n",
    "The dataset from Kaggle gives us a 784 feature vector for each of the images. This corresponds to the 28 pixel height and width of all the images. The following code will turn this array into a 3-dimensional array. Besides the height and width of an image we have to take care of its color (usually). Here the images are gray scaled instead of RGB. In case of a colored picture we would have 784x3 = 2352 features per image. \n",
    "In this case we will therefore have 42000 28x28x1 matrices in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1), the first dimension of X_train/test is samples\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding\n",
    "One-hot encoding of target label. Instead of one number, which can take on values between 0 and 9, we will have a one-hot-vector for each observation with 10 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train_value = Y_train # keep the origianl label\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "Y_train.shape\n",
    "#Y_train_value = np.argmax(Y_train, axis=1) # keep the origianl label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADQxJREFUeJzt3X/oXfV9x/FnFp1smj8aRJvGbLrWvonLWNpUKWQ6rVh0WGIRf5bWQbH7I/5RFIdYrbJhkaXqhBVnrSERokZIrbboVslc1f5hQ5zUaHgH50Rjvks6IjRb19bE7I97I1n83nO/+d5zfyTv5wPCvfe877n3nUNeOfeezzn3M2f//v1IOvr9zrgbkDQahl0qwrBLRRh2qYhjRvVGEXEccCYwBewb1ftKhcwFFgCbMvM3hxZHFnY6QX9+hO8nVXU28MKhCwcKe0RcCNxL53+U72XmnQ1PnwLY/s7/sHefw31S246ZO4dTFh4P3ax9qD7bF46IucB3gAuA7cCmiHgyM1/rsco+gL379rN3r2GXhmjar8mDHKA7C3g9M9/IzN8CjwIrBng9SUM0SNgXAm8f9Hh7d5mkCTRI2OdMs8zP59KEGiTs24FFBz0+BdgxWDuShmWQo/GbgNMj4jTgHeBK4OpWupLUulnv2TNzL3Ad8M/AVuCxzHy1rcYktWugcfbMfAp4qqVeJA2R58ZLRRh2qQjDLhVh2KUiDLtUhGGXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRhl0qwrBLRRh2qQjDLhVh2KUiDLtUxECzuOrod+mCMxvr35r3v431P/zX+3rW3nv0rsZ139u8rbF+7b8c31jfMLWpsV7NQGGPiDeBPcA+YG9mfqaFniQNQRt79vMy879aeB1JQ+R3dqmIQcO+H/hxRGyOiK+10ZCk4Rg07Msz89PARcDKiDinhZ4kDcFAYc/MHd3bXcDjwFltNCWpfbMOe0QcHxHzDtwHPg9saasxSe0a5Gj8ycDjEXHgdR7OzH9qpSuNzA/nN3/z+uS83Y31m/f8XmN9w8fOPuyeDvjbBec11tc+dH5j/Vsre58DENvq7ZdmHfbMfAP40xZ7kTREDr1JRRh2qQjDLhVh2KUiDLtUhJe4HgUWz1/Us/bTi+Y1rvvTp5tfe5xDVLdOPdtYf/iK1xvrTX/33Wee0bju/HWvNdaPRO7ZpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIx9mPAj+7ZVnP2o5/bB6L/sLu59puZ2S27n67sb786d7nH2xa/1eN6y5++v6B3nsSuWeXijDsUhGGXSrCsEtFGHapCMMuFWHYpSIcZz8C9Js2ec6f9J48N7b9oO12jhhXH/eJnrVj/vjPG9fduvuWttsZO/fsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SE4+xHgHWb726sf2nZ9SPqZLL0O//gxs1/M+vX/vWO5xvrv7qx+Xr4Sfzd+b5hj4jVwMXArsxc0l02H1gPnAq8CVyeme8Or01Jg5rJx/g1wIWHLLsJ2JiZpwMbu48lTbC+Yc/M54DdhyxeAazt3l8LXNJyX5JaNtsDdCdn5hRA9/ak9lqSNAwejZeKmG3Yd0bEAoDu7a72WpI0DLMN+5PANd371wBPtNOOpGGZydDbI8C5wIkRsR24DbgTeCwivgq8BVw2zCaPdv3Gi/vZMLWppU4mS7/t0u/8g0H0G0df/vSeob33sPQNe2Ze1aN0fsu9SBoiD9BJRRh2qQjDLhVh2KUiDLtUhJe4ToClnDDuFoamafhszY0LG9c99sobBnrv9x69q2ftL1e907juhqnJu0R1UO7ZpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIx9knwMv890DrN41lD3r56+L5ixrrP7tlWWO9aax876s/aVz3mSXfaKz/Nf/RWN+6++3GejXu2aUiDLtUhGGXijDsUhGGXSrCsEtFGHapCMfZJ0C/sfAH+vys8brN9/esvbbk6sZ1/47TGusXbLmjsd7PqmXf7Fm7derZgV5bh8c9u1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4V4Tj7EWD+uubfMP/1qt61f9vy8EDv7TXlR4+ZzM++GrgY2JWZS7rLbgeuBX7RfdrNmfnUsJqUNLiZ7NnXAP8APHTI8nsy89utdyRpKPp+Z8/M54DdI+hF0hANcoDuuoj4eUSsjoiPtNaRpKGYbdjvAz4OLAWmgN4z6EmaCLM6Gp+ZOw/cj4gHgB+11pGkoZjVnj0iFhz08IvAlnbakTQsMxl6ewQ4FzgxIrYDtwHnRsRSYD/wJtB8wbUG8sP558x63aY5yqH/HOiOox89+oY9M6+aZvGDQ+hF0hB5uqxUhGGXijDsUhGGXSrCsEtFeInrBNhz9yWN9fc2b2usf2nZ9T1r/X6m+tJV7zTWN61vHlV9Z+WjjfXY5ikYk8I9u1SEYZeKMOxSEYZdKsKwS0UYdqkIwy4V4Th7CxbPX9RYv/q4TzTW+42j9/sp6UH0G4d/7Yr/bKz3/anqj519uC1pSNyzS0UYdqkIwy4VYdilIgy7VIRhl4ow7FIRjrO3oN813/d8ZWNjfZjj6IPyp6KPHu7ZpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqkIx9lnaJBpk2+derbFTkar37X6OnLMZH72RcBDwEeB94HvZua9ETEfWA+cSmeO9ssz893htSppEDP5GL8XuCEzFwOfBVZGxBnATcDGzDwd2Nh9LGlC9Q17Zk5l5kvd+3uArcBCYAWwtvu0tUDzHEaSxuqwDtBFxKnAp4AXgZMzcwo6/yEAJ7XenaTWzDjsEXECsAH4emb+cngtSRqGGYU9Io6lE/R1mfn97uKdEbGgW18A7BpOi5LaMJOj8XOAB4GtmXn3QaUngWuAO7u3TwylwyNAv0tYJ1m/obV+l+/uffUnbbajIZrJOPty4MvAKxHxcnfZzXRC/lhEfBV4C7hsOC1KakPfsGfmC8CcHuXz221H0rB4uqxUhGGXijDsUhGGXSrCsEtFeInrDF2w5Y6etTXLrh9hJ4fn0gVnNtbXPrRioNc/84r7B1pfo+OeXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKcJx9hlYt+2bPWr+x6qVfOWGg9175uZ2N9d9fNfux7meWfKOx/oXdz836tTVZ3LNLRRh2qQjDLhVh2KUiDLtUhGGXijDsUhGOs89Q07TLl6/8ReO6Kz/3fmO93zj5r25s/u32pnMAHv7N643rbt39dmNdRw/37FIRhl0qwrBLRRh2qQjDLhVh2KUiDLtUxEzmZ18EPAR8FHgf+G5m3hsRtwPXAgcGmW/OzKeG1egki21bmp+wrc8LrDt7wA5eG3B9VTCTk2r2Ajdk5ksRMQ/YHBHPdGv3ZOa3h9eepLbMZH72KWCqe39PRGwFFg67MUntOqzv7BFxKvAp4MXuousi4ucRsToiPtJ2c5LaM+OwR8QJwAbg65n5S+A+4OPAUjp7/ruG0qGkVszoQpiIOJZO0Ndl5vcBMnPnQfUHgB8NpUNJrei7Z4+IOcCDwNbMvPug5QsOetoXgT6HpCWN00z27MuBLwOvRMTL3WU3A1dFxFJgP/Am0HwdpqSxmsnR+BeAOdOUSo6pS0cqz6CTijDsUhGGXSrCsEtFGHapCMMuFWHYpSIMu1SEYZeKMOxSEYZdKsKwS0UYdqmIUc7iOhfgmLnTXUAnaVAHZWvutPXRtcICgFMWHj/Ct5RKWgD8+6ELRxn2TcDZdH6vbt8I31eqYi6doG+arjhn//79o21H0lh4gE4qwrBLRRh2qQjDLhVh2KUiRjn09oGIuBC4l85Qwfcy885x9DGdiHgT2ENneHBvZn5mjL2sBi4GdmXmku6y+cB64FQ6v9d/eWa+OyG93c4ETOPdMM34WLfduKc/H/mePSLmAt8BLgLOoDPZxBmj7qOP8zJz6TiD3rUGuPCQZTcBGzPzdGBj9/E4rOHDvUFnGu+l3T/jmlvgwDTji4HPAiu7/8bGve169QUj2G7j+Bh/FvB6Zr6Rmb8FHgVWjKGPiZeZzwG7D1m8Aljbvb8WuGSkTXX16G0iZOZUZr7Uvb8HODDN+Fi3XUNfIzGOsC8E3j7o8XYma773/cCPI2JzRHxt3M1M4+TMnILOPx7gpDH3c6iJmsb7kGnGJ2bbjWP683GEfborYSbpNL7lmflpOl8zVkbEOeNu6AgyUdN4TzPN+EQY1/Tn4wj7dmDRQY9PAXaMoY9pZeaO7u0u4HE6Xzsmyc4DM+h2b3eNuZ8PZObOzNyXme8DDzDGbTfdNONMwLbrNf35KLbbOMK+CTg9Ik6LiN8FrgSeHEMfHxIRx0fEvAP3gc8zeVNRPwlc071/DfDEGHv5fyZlGu9e04wz5m037unPx3IhTET8BfD3dIbeVmfmHSNvYhoR8Ud09ubQGZZ8eJy9RcQjwLnAicBO4DbgB8BjwB8AbwGXZebID5T16O1cOh9FP5jG+8B35BH39mfA88ArdIa4oDPN+IuMcds19HUVI9huXvUmFeEZdFIRhl0qwrBLRRh2qQjDLhVh2KUiDLtUxP8Bpd1/WnaAxZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some examples\n",
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mdelling the convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 814,970\n",
      "Trainable params: 814,778\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> [Dense -> Dropout]*2 -> Softmax\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n",
    "                 input_shape = (28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "\n",
    "# Turn epochs to 30 to get 0.9967 accuracy\n",
    "epochs = 30 \n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1)  # randomly shift images vertically (fraction of total height)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 99s - loss: 0.4636 - acc: 0.8505 - val_loss: 0.0981 - val_acc: 0.9702\n",
      "Epoch 2/30\n",
      " - 89s - loss: 0.1487 - acc: 0.9549 - val_loss: 0.0501 - val_acc: 0.9838\n",
      "Epoch 3/30\n",
      " - 115s - loss: 0.1131 - acc: 0.9647 - val_loss: 0.0398 - val_acc: 0.9883\n",
      "Epoch 4/30\n",
      " - 95s - loss: 0.0960 - acc: 0.9709 - val_loss: 0.0422 - val_acc: 0.9874\n",
      "Epoch 5/30\n",
      " - 98s - loss: 0.0823 - acc: 0.9758 - val_loss: 0.0267 - val_acc: 0.9907\n",
      "Epoch 6/30\n",
      " - 89s - loss: 0.0732 - acc: 0.9782 - val_loss: 0.0341 - val_acc: 0.9893\n",
      "Epoch 7/30\n",
      " - 133s - loss: 0.0733 - acc: 0.9783 - val_loss: 0.0299 - val_acc: 0.9898\n",
      "Epoch 8/30\n",
      " - 140s - loss: 0.0586 - acc: 0.9820 - val_loss: 0.0213 - val_acc: 0.9919\n",
      "Epoch 9/30\n",
      " - 141s - loss: 0.0587 - acc: 0.9825 - val_loss: 0.0225 - val_acc: 0.9933\n",
      "Epoch 10/30\n",
      " - 135s - loss: 0.0528 - acc: 0.9840 - val_loss: 0.0207 - val_acc: 0.9933\n",
      "Epoch 11/30\n",
      " - 105s - loss: 0.0481 - acc: 0.9850 - val_loss: 0.0150 - val_acc: 0.9955\n",
      "Epoch 12/30\n",
      " - 105s - loss: 0.0480 - acc: 0.9850 - val_loss: 0.0160 - val_acc: 0.9940\n",
      "Epoch 13/30\n",
      " - 121s - loss: 0.0446 - acc: 0.9862 - val_loss: 0.0198 - val_acc: 0.9938\n",
      "Epoch 14/30\n",
      " - 127s - loss: 0.0423 - acc: 0.9878 - val_loss: 0.0177 - val_acc: 0.9952\n",
      "Epoch 15/30\n",
      " - 134s - loss: 0.0420 - acc: 0.9872 - val_loss: 0.0224 - val_acc: 0.9938\n",
      "Epoch 16/30\n",
      " - 127s - loss: 0.0389 - acc: 0.9881 - val_loss: 0.0155 - val_acc: 0.9945\n",
      "Epoch 17/30\n",
      " - 109s - loss: 0.0379 - acc: 0.9888 - val_loss: 0.0155 - val_acc: 0.9955\n",
      "Epoch 18/30\n",
      " - 132s - loss: 0.0361 - acc: 0.9892 - val_loss: 0.0186 - val_acc: 0.9945\n",
      "Epoch 19/30\n",
      " - 132s - loss: 0.0359 - acc: 0.9893 - val_loss: 0.0144 - val_acc: 0.9952\n",
      "Epoch 20/30\n",
      " - 119s - loss: 0.0323 - acc: 0.9900 - val_loss: 0.0180 - val_acc: 0.9948\n",
      "Epoch 21/30\n",
      " - 101s - loss: 0.0328 - acc: 0.9899 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 22/30\n",
      " - 114s - loss: 0.0318 - acc: 0.9904 - val_loss: 0.0148 - val_acc: 0.9957\n",
      "Epoch 23/30\n",
      " - 134s - loss: 0.0309 - acc: 0.9902 - val_loss: 0.0156 - val_acc: 0.9960\n",
      "Epoch 24/30\n",
      " - 143s - loss: 0.0304 - acc: 0.9905 - val_loss: 0.0172 - val_acc: 0.9952\n",
      "Epoch 25/30\n",
      " - 142s - loss: 0.0297 - acc: 0.9909 - val_loss: 0.0147 - val_acc: 0.9960\n",
      "Epoch 26/30\n",
      " - 143s - loss: 0.0293 - acc: 0.9907 - val_loss: 0.0173 - val_acc: 0.9957\n",
      "Epoch 27/30\n",
      " - 132s - loss: 0.0289 - acc: 0.9913 - val_loss: 0.0178 - val_acc: 0.9955\n",
      "Epoch 28/30\n",
      " - 108s - loss: 0.0289 - acc: 0.9908 - val_loss: 0.0159 - val_acc: 0.9955\n",
      "Epoch 29/30\n",
      " - 142s - loss: 0.0272 - acc: 0.9918 - val_loss: 0.0165 - val_acc: 0.9957\n",
      "Epoch 30/30\n",
      " - 104s - loss: 0.0281 - acc: 0.9917 - val_loss: 0.0157 - val_acc: 0.9960\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[annealer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
